{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FirstNeuralNetwork1layer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNd50sNItahCUNT+4VXqD0r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emadfrj/NeuralNetwork1layer/blob/main/FirstNeuralNetwork1layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork1layer:\n",
        "    def __init__(self, learning_rate):\n",
        "        self.weights = np.array([np.random.randn(), np.random.randn()])\n",
        "        self.bias = np.random.randn()\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def _Dsigmoid(self, x):\n",
        "        return self._sigmoid(x) * (1 - self._sigmoid(x))\n",
        "\n",
        "    def predict(self, input_vector):\n",
        "        layer_1 = np.dot(input_vector, self.weights) + self.bias\n",
        "        layer_2 = self._sigmoid(layer_1)\n",
        "        prediction = layer_2\n",
        "        return prediction\n",
        "\n",
        "    def _compute_gradients(self, input_vector, target):\n",
        "        layer_1 = np.dot(input_vector, self.weights) + self.bias\n",
        "        layer_2 = self._sigmoid(layer_1)\n",
        "        prediction = layer_2\n",
        "\n",
        "        derror_dprediction = 2 * (prediction - target)\n",
        "        dprediction_dlayer1 = self._Dsigmoid(layer_1)\n",
        "        dlayer1_dbias = 1\n",
        "        dlayer1_dweights = (0 * self.weights) + (1 * input_vector)\n",
        "\n",
        "        derror_dbias = (\n",
        "            derror_dprediction * dprediction_dlayer1 * dlayer1_dbias\n",
        "        )\n",
        "        derror_dweights = (\n",
        "            derror_dprediction * dprediction_dlayer1 * dlayer1_dweights\n",
        "        )\n",
        "\n",
        "        return derror_dbias, derror_dweights\n",
        "\n",
        "    def _update_parameters(self, derror_dbias, derror_dweights):\n",
        "        self.bias = self.bias - (derror_dbias * self.learning_rate)\n",
        "        self.weights = self.weights - (\n",
        "            derror_dweights * self.learning_rate\n",
        "        )\n",
        "\n",
        "    def train(self, input_vectors, targets, iterations):\n",
        "        inputLen = len(input_vectors)\n",
        "        cumulative_errors = []\n",
        "        for current_iteration in range(iterations):\n",
        "            random_data_index = np.random.randint(inputLen)\n",
        "            input_vector = input_vectors[random_data_index]\n",
        "            target = targets[random_data_index]\n",
        "            derror_dbias, derror_dweights = self._compute_gradients(input_vector,target)\n",
        "            self._update_parameters(derror_dbias,derror_dweights)\n",
        "            if current_iteration % 100==0:\n",
        "                cumulative_error = 0\n",
        "                # Loop through all the instances to measure the error\n",
        "                for data_instance_index in range(inputLen):\n",
        "                    data_point = input_vectors[data_instance_index]\n",
        "                    target = targets[data_instance_index]\n",
        "\n",
        "                    prediction = self.predict(data_point)\n",
        "                    error = np.square(prediction - target)\n",
        "\n",
        "                    cumulative_error = cumulative_error + error\n",
        "                cumulative_errors.append(cumulative_error)\n",
        "        return cumulative_errors"
      ],
      "metadata": {
        "id": "58Guiob0CMFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "input_vectors = np.random.normal(size=[100, 2])\n",
        "targets = np.random.normal(size=[100, 1])\n",
        "\n",
        "learning_rate = 0.1\n",
        "\n",
        "neural_network = NeuralNetwork1layer(learning_rate)\n",
        "\n",
        "training_error = neural_network.train(input_vectors, targets, 10000)\n",
        "\n",
        "plt.plot(training_error)\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Error for all training instances\")\n",
        "plt.savefig(\"cumulative_error.png\")"
      ],
      "metadata": {
        "id": "9HOR7lzxClU5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}